# -*- coding: utf-8 -*-
"""hybrid-model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_vhfi-1lJipUR1xxcZ44_CL6Q0j5a120
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

dataset = pd.read_csv('/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')

df=pd.DataFrame(dataset)

df.columns

columns_to_drop=[ ' Fwd Packet Length Max',' Fwd Packet Length Std','Flow Bytes/s',
                 ' Flow Packets/s',' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',
                 'Fwd IAT Total',  ' Fwd IAT Std', ' Fwd IAT Max',' Fwd IAT Min',
                  'Bwd IAT Total', ' Fwd Header Length',' Bwd Header Length',
                  ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',
                 ' Packet Length Std', ' Packet Length Variance', ' Average Packet Size',
                  ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',' Fwd Header Length.1',
                  'Subflow Fwd Packets', ' Subflow Fwd Bytes',' Subflow Bwd Packets',
                  ' Subflow Bwd Bytes','Init_Win_bytes_forward',' Init_Win_bytes_backward',
                  ' act_data_pkt_fwd',' min_seg_size_forward']

df = df.drop(columns=columns_to_drop)

df.columns

# Feature Selection/Engineering (if needed)
# Select relevant features or engineer new ones based on your problem.
selected_features = [' Destination Port',' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',
       ' Total Length of Bwd Packets','Total Length of Fwd Packets', ' Fwd Packet Length Mean',' Bwd Packet Length Mean',
       ' Flow IAT Mean', ' Fwd IAT Mean', 'Fwd Packets/s',' Bwd Packets/s',  ' Label']
# Create a new DataFrame with selected features
dataset_selected = dataset[selected_features]

# Split the data into features (X) and labels (y)
X = dataset.drop(' Label', axis=1)
y = dataset[' Label']

df.info()

print(df.isnull().sum())  # Check for NaN values
print(df[df.isin([np.inf, -np.inf]).any(1)])  # Check for infinite values

#import numpy as np
#df.replace([np.inf, -np.inf], np.nan, inplace=True)
# df.fillna(df.mean(), inplace=True)
df.fillna(df.mean(numeric_only=True), inplace=True)

print(df.isnull().sum())  # Check for NaN values

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder


# 1. Scaling or Normalizing Features
# Assuming you want to use StandardScaler
scaler = StandardScaler()
X_normalized = scaler.fit_transform(df[[' Destination Port',' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',
       ' Total Length of Bwd Packets','Total Length of Fwd Packets', ' Fwd Packet Length Mean',' Bwd Packet Length Mean',
       ' Flow IAT Mean', ' Fwd IAT Mean', 'Fwd Packets/s',' Bwd Packets/s',]])

# 2. Encoding Categorical Variables (if applicable)
# Let's assume 'Category' is a categorical column
label_encoder = LabelEncoder()
df['Category_encoded'] = label_encoder.fit_transform(df[' Label'])

# If 'Category' is nominal and you want to use one-hot encoding, you can use pandas' get_dummies method
# df_encoded = pd.get_dummies(df, columns=['Category'], drop_first=True)

# Now, 'df' contains the preprocessed data with missing values filled, features scaled, and categorical variables encoded.

df.head()

from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle

X_train, X_test, y_train, y_test = train_test_split(X_normalized, df['Category_encoded'], test_size=0.35, random_state=42)
X_train, y_train = shuffle(X_train, y_train, random_state=42)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)

#gru
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization
from tensorflow.keras.regularizers import l2
from sklearn.metrics import accuracy_score
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping


# Assuming you have already loaded your data (X_train, y_train, X_test, y_test) properly

# Reshape data for GRU layer
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

model_GRU = Sequential()
model_GRU.add(GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))
model_GRU.add(GRU(128, return_sequences=True))
model_GRU.add(GRU(64))
model_GRU.add(BatchNormalization())
model_GRU.add(Dropout(0.6))
model_GRU.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))

# Implement learning rate scheduling
initial_learning_rate = 0.0005
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps=10, decay_rate=0.9)
optimizer = Adam(learning_rate=lr_schedule)
model_GRU.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Implement early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model with validation data
model_GRU.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test), callbacks=[early_stopping])

# Evaluate the model on the test set
y_pred = model_GRU.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

# Calculate accuracy
accuracy_GRU = accuracy_score(y_test, y_pred_binary)
print(f'Improved Accuracy: {accuracy_GRU}')

from sklearn.metrics import accuracy_score, f1_score

# Evaluate the model on the test set
y_pred = model_GRU.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

# Calculate accuracy
accuracy_GRU = accuracy_score(y_test, y_pred_binary)

# Calculate F1 score
f1_GRU = f1_score(y_test, y_pred_binary)

print(f'Improved Accuracy: {accuracy_GRU}')
print(f'F1 Score: {f1_GRU}')

from sklearn.metrics import precision_score, recall_score, confusion_matrix

# Assuming y_test and y_pred_gru are the true labels and predictions for the GRU model
conf_matrix_gru = confusion_matrix(y_test, y_pred_binary)

precision_gru = precision_score(y_test, y_pred_binary)
recall_gru = recall_score(y_test, y_pred_binary)

print(f"Precision (GRU): {precision_gru}")
print(f"Recall (GRU): {recall_gru}")

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
# Assuming you have the following variables
# y_test: True labels for the test set
# y_pred_binary: Predicted labels for the test set

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_binary)
conf_matrix_GRU = confusion_matrix(y_test, y_pred_binary)
print('Confusion Matrix:')
print(conf_matrix_GRU)
# Plot confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_GRU, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'DDoS'], yticklabels=['Normal', 'DDoS'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import SGD
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score

# Assuming X_train and X_test are your normalized features
X_train, X_test, y_train, y_test = train_test_split(X_normalized, df['Category_encoded'], test_size=0.35, random_state=42)
X_train, y_train = shuffle(X_train, y_train, random_state=42)

# Build the CNN model with a specified learning rate
learning_rate = 0.001  # Set your desired learning rate here

model_CNN = Sequential()
model_CNN.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))
model_CNN.add(Dropout(0.2))
model_CNN.add(Conv1D(128, kernel_size=3, activation='relu'))
model_CNN.add(MaxPooling1D(pool_size=2))
model_CNN.add(Flatten())
model_CNN.add(Dense(64, activation='relu'))
model_CNN.add(Dropout(0.5))
model_CNN.add(Dense(1, activation='sigmoid'))

# Use SGD optimizer with the specified learning rate
optimizer = SGD(learning_rate=learning_rate)

# Compile the model with the specified optimizer
model_CNN.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Train the model with early stopping and dropout
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

model_CNN.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2, callbacks=[early_stopping])

# Evaluate the model on the test set
y_pred = model_CNN.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

# Calculate accuracy
accuracy_CNN = accuracy_score(y_test, y_pred_binary)
print(f'Accuracy: {accuracy_CNN}')

# Assuming y_test and y_pred_cnn are the true labels and predictions for the CNN model
conf_matrix_cnn = confusion_matrix(y_test, y_pred_binary)

precision_cnn = precision_score(y_test, y_pred_binary)
recall_cnn = recall_score(y_test, y_pred_binary)

print(f"Precision (CNN): {precision_cnn}")
print(f"Recall (CNN): {recall_cnn}")

from sklearn.metrics import f1_score, confusion_matrix

# Evaluate the model on the test set
y_pred = model_CNN.predict(X_test)
y_pred_binary = (y_pred > 0.5).astype(int)

# Calculate accuracy
accuracy_CNN = accuracy_score(y_test, y_pred_binary)
print(f'Accuracy: {accuracy_CNN}')

# Calculate F1 score
f1_CNN = f1_score(y_test, y_pred_binary)
print(f'F1 Score: {f1_CNN}')

# Calculate confusion matrix
conf_matrix_CNN = confusion_matrix(y_test, y_pred_binary)
print('Confusion Matrix:')
print(conf_matrix_CNN)
# Plot confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_CNN, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'DDoS'], yticklabels=['Normal', 'DDoS'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# print("Shapes - X_test_reshaped:", X_test_reshaped.shape, "y_pred:", y_pred.shape, "y_test_trimmed:", y_test_trimmed.shape)

from tensorflow.keras.layers import Input, Concatenate, Dense
from tensorflow.keras.models import Model
# Create input layers for the functional API
input_CNN = Input(shape=(X_train.shape[1], 1))
input_GRU = Input(shape=(X_train.shape[1], 1))

# Get the output of each model given their respective input
output_CNN = model_CNN(input_CNN)
output_GRU = model_GRU(input_GRU)

# Combine CNN and GRU outputs
combined_output = Concatenate()([output_CNN, output_GRU])
combined_output = Dense(1, activation='sigmoid')(combined_output)

# Create the hybrid model using functional API
model_hybrid = Model(inputs=[input_CNN, input_GRU], outputs=combined_output)

# Compile the model
optimizer = Adam(learning_rate=0.0005)
model_hybrid.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Train the model with early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Assuming X_train_reshaped and X_test_reshaped are the reshaped inputs for GRU and CNN respectively
model_hybrid.fit([X_train, X_train], y_train, epochs=5, batch_size=64,
                 validation_data=([X_test, X_test], y_test), callbacks=[early_stopping])

# Evaluate the model on the test set
y_pred = model_hybrid.predict([X_test, X_test])
y_pred_binary = (y_pred > 0.5).astype(int)

# Calculate accuracy
accuracy_hybrid = accuracy_score(y_test, y_pred_binary)
print(f'Hybrid Model Accuracy: {accuracy_hybrid}')

f1_hybrid = f1_score(y_test, y_pred_binary)

# Generate confusion matrix
conf_matrix_hybrid = confusion_matrix(y_test, y_pred_binary)

# Plot heatmap for confusion matrix
sns.heatmap(conf_matrix_hybrid, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print(f'F1 Score: {f1_hybrid}')

# Assuming y_test and y_pred_hybrid are the true labels and predictions for the hybrid model
conf_matrix_hybrid = confusion_matrix(y_test, y_pred_binary)

precision_hybrid = precision_score(y_test, y_pred_binary)
recall_hybrid = recall_score(y_test, y_pred_binary)

print(f"Precision (Hybrid): {precision_hybrid}")
print(f"Recall (Hybrid): {recall_hybrid}")

model_hybrid.summary()